{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word Prediction\n",
    "\n",
    "In this notebook, we are going to predict the next word that the writer is going to write. This will help us evaluate that how much the neural network has understood about dependencies between different letters that combine to form a word. We can also get an idea of how much the model has understood about the order of different types of word in a sentence.\n",
    "\n",
    "Code segments [1] to [5] are same as that in 'train.ipynb' notebook and their detailed explanation can be found over their itself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, LSTM, Dropout, Activation\n",
    "from keras.optimizers import RMSprop, Adam\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.utils import np_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "SEQ_LENGTH = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def buildmodel(VOCABULARY):\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(256, input_shape = (SEQ_LENGTH, 1), return_sequences = True))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(LSTM(256))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(VOCABULARY, activation = 'softmax'))\n",
    "    model.compile(loss = 'categorical_crossentropy', optimizer = 'adam')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "file = open('wonderland.txt', encoding = 'utf8')\n",
    "raw_text = file.read()\n",
    "raw_text = raw_text.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['\\n', ' ', '!', '#', '$', '%', '(', ')', '*', ',', '-', '.', '/', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', ':', ';', '?', '@', '[', ']', '_', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', '‘', '’', '“', '”', '\\ufeff']\n",
      "['\\n', ' ', '!', '$', '%', '(', ')', ',', '-', '.', '/', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', ':', ';', '?', '[', ']', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', '‘', '’', '“', '”']\n"
     ]
    }
   ],
   "source": [
    "chars = sorted(list(set(raw_text)))\n",
    "print(chars)\n",
    "bad_chars = ['#', '*', '@', '_', '\\ufeff']\n",
    "for i in range(len(bad_chars)):\n",
    "    raw_text = raw_text.replace(bad_chars[i],\"\")\n",
    "chars = sorted(list(set(raw_text)))\n",
    "print(chars)\n",
    "VOCABULARY = len(chars)\n",
    "\n",
    "int_to_char = dict((i, c) for i, c in enumerate(chars))\n",
    "char_to_int = dict((c, i) for i, c in enumerate(chars))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that our model has been defined and we have preprocessed our input file and redefinded our vocabulary, as in train.ipynb file we are ready to proceed. The best model with least loss as we obtained in the last epoch of training is loaded and the model is build and recompiled."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "filename = 'saved_models/weights-improvement-49-1.3420.hdf5'\n",
    "model = buildmodel(VOCABULARY)\n",
    "model.load_weights(filename)\n",
    "model.compile(loss = 'categorical_crossentropy', optimizer = 'adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from ipywidgets import widgets\n",
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The original model has been defined in a manner to take in 100 character inputs. So when the user initially starts typing the words, the total length of input string will be less than 100 characters. To solve this issue, the input has been padded with series of spaces in the beginning in ordert to make the total length of 100 characters. As the total length exceeds 100 characters, only last 100 characters as the LSTM nodes take care of remembering the context of the document from before.\n",
    "\n",
    "Succeeding characters are predicted by the model until a space or full stop is encountered. The predicted characters are joined to form the next word, predicted by the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d3b3475b7cec4002ad8800c710fb958e"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ’ | of | y | a | the | dia | out | see | it | see | and | she | kean | the | a | wind, | of | the | would | and | it |  | and | shink | an | was | i | and | dou’e | the | at | hear | of | the | hear | thing | to | heard | the | hev | at | must | do | you |"
     ]
    }
   ],
   "source": [
    "original_text = []\n",
    "predicted_text = []\n",
    "\n",
    "text = widgets.Text()\n",
    "display(text)\n",
    "\n",
    "def handle_submit(sender):\n",
    "    global predicted_text\n",
    "    global original_text\n",
    "    \n",
    "    inp = list(text.value)\n",
    "    \n",
    "    last_word = inp[len(original_text):]\n",
    "    inp = inp[:len(original_text)]    \n",
    "    original_text = text.value    \n",
    "    last_word.append(' ')\n",
    "    \n",
    "    inp_text = [char_to_int[c] for c in inp]\n",
    "    last_word = [char_to_int[c] for c in last_word]\n",
    "    \n",
    "    if len(inp_text) > 100:\n",
    "        inp_text = inp_text[len(inp_text)-100: ]\n",
    "    if len(inp_text) < 100:\n",
    "        pad = []\n",
    "        space = char_to_int[' ']\n",
    "        pad = [space for i in range(100-len(inp_text))]\n",
    "        inp_text = pad + inp_text\n",
    "    \n",
    "    while len(last_word)>0:\n",
    "        X = np.reshape(inp_text, (1, SEQ_LENGTH, 1))\n",
    "        next_char = model.predict(X/float(VOCABULARY))\n",
    "        inp_text.append(last_word[0])\n",
    "        inp_text = inp_text[1:]\n",
    "        last_word.pop(0)\n",
    "    \n",
    "    next_word = []\n",
    "    next_char = ':'\n",
    "    while next_char != ' ':\n",
    "        X = np.reshape(inp_text, (1, SEQ_LENGTH, 1))\n",
    "        next_char = model.predict(X/float(VOCABULARY))\n",
    "        index = np.argmax(next_char)        \n",
    "        next_word.append(int_to_char[index])\n",
    "        inp_text.append(index)\n",
    "        inp_text = inp_text[1:]\n",
    "        next_char = int_to_char[index]\n",
    "    \n",
    "    predicted_text = predicted_text + [''.join(next_word)]\n",
    "    print(\" \" + ''.join(next_word), end='|')\n",
    "    \n",
    "text.on_submit(handle_submit)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The text box above shows the text as written by the user. The text used over here is the first few characters of the famous children book 'The Cat in the Hat' by Dr. Seuss available [here](http://www.stylist.co.uk/books/100-best-opening-lines-from-childrens-books#gallery-1). As the text is typed over, pressing enter just after the character ends (before the space), gives us the next word suggesstion, followed by a vertical bar to seperate the words, as shown above and in the gif.\n",
    "\n",
    "Next we summarize the predictions made by the model, in a nice tabular form listing the actual word typed by the user and the word suggessted by the model, before typing it side by side as shown after the code segment below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actual Word    Predicted Word\n",
      "-------------  ----------------\n",
      "the\n",
      "sun            ’\n",
      "did            of\n",
      "not            y\n",
      "shine,         a\n",
      "it             the\n",
      "was            dia\n",
      "too            out\n",
      "wet            see\n",
      "to             it\n",
      "play,          see\n",
      "so             and\n",
      "we             she\n",
      "sat            kean\n",
      "in             the\n",
      "the            a\n",
      "house          wind,\n",
      "all            of\n",
      "that           the\n",
      "cold,          would\n",
      "cold           and\n",
      "wet            it\n",
      "day.\n",
      "i              and\n",
      "sat            shink\n",
      "there          an\n",
      "with           was\n",
      "sally.         i\n",
      "we             and\n",
      "sat            dou’e\n",
      "here           the\n",
      "we             at\n",
      "two            hear\n",
      "and            of\n",
      "we             the\n",
      "said           hear\n",
      "how            thing\n",
      "we             to\n",
      "wish           heard\n",
      "we             the\n",
      "had            hev\n",
      "something      at\n",
      "to             must\n",
      "do.            do\n"
     ]
    }
   ],
   "source": [
    "from tabulate import tabulate\n",
    "\n",
    "original_text = original_text.split()\n",
    "predicted_text.insert(0,\"\")\n",
    "predicted_text.pop()\n",
    "\n",
    "table = []\n",
    "for i in range(len(original_text)):\n",
    "    table.append([original_text[i], predicted_text[i]])\n",
    "print(tabulate(table, headers = ['Actual Word', 'Predicted Word']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Conclusions\n",
    "A lot of observations can be made from the table above-\n",
    "* Most of the words generated by the model are proper english words, although there are exceptions at many places. This shows that the model has a good understanding of how letters are combined to form different words. Even though it is very obvious to do for a human, but for a computer model to give a reasonable performance at word formation is itself a huge feat.\n",
    "* The model has also understood to some extent about grammar of english language. In the above case, we can see that it often suggests verb at place of a verb like 'wet to see' in place of 'wet to play'. Also many a times, words of other part of speech are suggessted but they fit well, for example, 'we sat in the wind' is suggessted in place of 'we sat in the house'. Relationships like this show great hope, although the model has to further learn a lot in this area.\n",
    "* There are a few drawbacks as well. One of them is that the model often suggests 'and', both after a comma and a full stop which may be correct in case 1, but is always wrong for case 2.\n",
    "\n",
    "Overall, this makes up a nice demonstration for word prediction using RNNs with LSTM nodes. Seeing the performance of these models show that how advanced models phone keyboard suggestions use, which are very accurate. Further improvements in this model can be made by further training, tuning the hyperparameters, using a deeper network etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
